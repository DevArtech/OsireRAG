<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.0"/>
    <title>OsireRAG API Documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../models.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;app.core.models</a>


            <div style="display: flex; align-items: center;">
<img src="../../../../icon.png" width="64" height="64"></img>
<h1>OsireRAG</h1>
</div>
<input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#TokenizedChunk">TokenizedChunk</a>
                            <ul class="memberlist">
                        <li>
                                <a class="variable" href="#TokenizedChunk.tokens">tokens</a>
                        </li>
                        <li>
                                <a class="variable" href="#TokenizedChunk.model_config">model_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ChunkTokenizer">ChunkTokenizer</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ChunkTokenizer.__init__">ChunkTokenizer</a>
                        </li>
                        <li>
                                <a class="variable" href="#ChunkTokenizer.stop_words">stop_words</a>
                        </li>
                        <li>
                                <a class="variable" href="#ChunkTokenizer.lemmatizer">lemmatizer</a>
                        </li>
                        <li>
                                <a class="class" href="#ChunkTokenizer.Config">ChunkTokenizer.Config</a>
                                        <ul class="memberlist">
                                    <li>
                                            <a class="variable" href="#ChunkTokenizer.Config.arbitrary_types_allowed">arbitrary_types_allowed</a>
                                    </li>
                            </ul>

                        </li>
                        <li>
                                <a class="function" href="#ChunkTokenizer.tokenize_query">tokenize_query</a>
                        </li>
                        <li>
                                <a class="function" href="#ChunkTokenizer.tokenize_documents">tokenize_documents</a>
                        </li>
                        <li>
                                <a class="variable" href="#ChunkTokenizer.model_config">model_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#BM25Model">BM25Model</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#BM25Model.create_model">create_model</a>
                        </li>
                        <li>
                                <a class="function" href="#BM25Model.load_model">load_model</a>
                        </li>
                        <li>
                                <a class="function" href="#BM25Model.search">search</a>
                        </li>
                        <li>
                                <a class="variable" href="#BM25Model.model_config">model_config</a>
                        </li>
                </ul>

            </li>
    </ul>



        

            

                

                

        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../../app.html">app</a><wbr>.<a href="./../../core.html">core</a><wbr>.<a href="./../models.html">models</a><wbr>.term_freq_retriever    </h1>

                        <div class="docstring"><p>Module: term_freq_retriever.py</p>

<p>Classes:</p>

<ul>
<li>TokenizedChunk: A Pydantic model for a text chunk with tokenized content.</li>
<li>ChunkTokenizer: A Pydantic model for tokenizing queries and document chunks.</li>
<li>BM25Model: A Pydantic model for creating, loading, and searching BM25 indices.</li>
</ul>

<p>Functions:</p>

<ul>
<li>None</li>
</ul>

<p>Usage:</p>

<ul>
<li>Import the BM25Model and ChunkTokenizer classes from this module to tokenize documents and perform BM25 searches.</li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>

                        <input id="mod-term_freq_retriever-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-term_freq_retriever-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="sd">Module: term_freq_retriever.py</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="sd">Classes:</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="sd">- TokenizedChunk: A Pydantic model for a text chunk with tokenized content.</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="sd">- ChunkTokenizer: A Pydantic model for tokenizing queries and document chunks.</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="sd">- BM25Model: A Pydantic model for creating, loading, and searching BM25 indices.</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a><span class="sd">Functions:</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a><span class="sd">- None</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a><span class="sd">Usage:</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="sd">- Import the BM25Model and ChunkTokenizer classes from this module to tokenize documents and perform BM25 searches.</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a><span class="sd">Author: Adam Haile  </span>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a><span class="sd">Date: 10/23/2024</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a><span class="kn">import</span> <span class="nn">nltk</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a><span class="kn">import</span> <span class="nn">pickle</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a><span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a><span class="kn">from</span> <span class="nn">rank_bm25</span> <span class="kn">import</span> <span class="n">BM25Okapi</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a><span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">ClassVar</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a><span class="kn">from</span> <span class="nn">app.core.models.chunker</span> <span class="kn">import</span> <span class="n">Chunk</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a><span class="k">class</span> <span class="nc">TokenizedChunk</span><span class="p">(</span><span class="n">Chunk</span><span class="p">):</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a><span class="sd">    A Pydantic model for a chunk of text with tokenized content.</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a><span class="sd">    Attributes:</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a><span class="sd">    - tokens: List[str]: A list of tokens representing the tokenized content of the chunk.</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a><span class="sd">    Usage:</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a><span class="sd">    - Use this class to represent a text chunk after tokenization.</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a><span class="sd">    Author: Adam Haile  </span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a><span class="sd">    Date: 10/23/2024</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a><span class="k">class</span> <span class="nc">ChunkTokenizer</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a><span class="sd">    A Pydantic model for tokenizing queries and document chunks.</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a><span class="sd">    Attributes:</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a><span class="sd">    - stop_words: set: A set of stop words to exclude during tokenization.</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a><span class="sd">    - lemmatizer: Any: A WordNetLemmatizer instance for lemmatizing tokens.</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a><span class="sd">    Methods:</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a><span class="sd">    - tokenize_query: Tokenizes and lemmatizes a query string.</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a><span class="sd">    - tokenize_documents: Tokenizes and lemmatizes the content of document chunks.</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a><span class="sd">    Usage:</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a><span class="sd">    - Instantiate this class to tokenize queries and document chunks for BM25.</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a><span class="sd">    Author: Adam Haile  </span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a><span class="sd">    Date: 10/23/2024</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a>    <span class="n">stop_words</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="nb">set</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">))</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a>    <span class="n">lemmatizer</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="n">WordNetLemmatizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a>    <span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>        <span class="n">arbitrary_types_allowed</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a><span class="sd">        Initializes the tokenizer with custom NLTK data path.</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a><span class="sd">        Raises:</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a><span class="sd">        - None</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a><span class="sd">        Usage:</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a><span class="sd">        - tokenizer = ChunkTokenizer()</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a>        <span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;./nltk_data&quot;</span><span class="p">))</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a>    <span class="k">def</span> <span class="nf">tokenize_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a><span class="sd">        Tokenizes and lemmatizes a query string.</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a><span class="sd">        Args:</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a><span class="sd">        - `query (str)`: The query to tokenize.</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a><span class="sd">        Returns:</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a><span class="sd">        - List[str]: A list of lemmatized tokens from the query.</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a><span class="sd">        Usage:</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a><span class="sd">        - `tokens = tokenizer.tokenize_query(&quot;example query&quot;)`</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a>        <span class="c1"># Tokenize and lemmatize the query</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a>        <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a>            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a>            <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_words</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a>        <span class="p">]</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a>        <span class="k">return</span> <span class="n">tokens</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a>    <span class="k">def</span> <span class="nf">tokenize_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Chunk</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">]:</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a><span class="sd">        Tokenizes and lemmatizes the content of document chunks.</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a><span class="sd">        Args:</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a><span class="sd">        - `chunks (List[Chunk])`: The list of document chunks to tokenize.</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a><span class="sd">        Returns:</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a><span class="sd">        - List[TokenizedChunk]: A list of TokenizedChunk objects.</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a><span class="sd">        Usage:</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a><span class="sd">        - `tokenized_chunks = tokenizer.tokenize_documents(chunks)`</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>        <span class="c1"># Tokenize and lemmatize the content of each chunk</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>        <span class="n">tokenized_docs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a>        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a>                <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_words</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a>            <span class="p">]</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a>            <span class="c1"># Append the tokenized chunk to the list</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a>            <span class="n">tokenized_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TokenizedChunk</span><span class="p">(</span><span class="n">tokens</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="o">**</span><span class="n">chunk</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()))</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a>        <span class="k">return</span> <span class="n">tokenized_docs</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a><span class="k">class</span> <span class="nc">BM25Model</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a><span class="sd">    A Pydantic model for creating, loading, and searching BM25 indices.</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a><span class="sd">    Methods:</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a><span class="sd">    - create_model: Creates and saves a BM25 model for a set of tokenized document chunks.</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a><span class="sd">    - load_model: Loads a BM25 model and tokenized documents from disk.</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a><span class="sd">    - search: Performs a BM25 search on a tokenized query.</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a><span class="sd">    Usage:</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a><span class="sd">    - Instantiate this class to create, load, and search BM25 indices.</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a><span class="sd">    Author: Adam Haile  </span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a><span class="sd">    Date: 10/23/2024</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a>    <span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>    <span class="p">):</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a><span class="sd">        Creates and saves a BM25 model for a set of tokenized document chunks.</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a><span class="sd">        Args:</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a><span class="sd">        - `project_name (str)`: The name of the project.</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a><span class="sd">        - `model_name (str)`: The name of the model.</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a><span class="sd">        - `chunks (List[TokenizedChunk])`: The list of tokenized document chunks.</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a><span class="sd">        - `kwargs (Dict[Any, Any])`: Additional arguments for BM25Okapi.</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a><span class="sd">        Returns:</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a><span class="sd">        - None</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a><span class="sd">        Raises:</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a><span class="sd">        - FileExistsError: If the model directory already exists.</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a><span class="sd">        Usage:</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a><span class="sd">        - `bm25.create_model(&quot;project&quot;, &quot;model&quot;, tokenized_chunks)`</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>        <span class="c1"># Create the model directory if it does not exist</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;./.OsireRAG&quot;</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>        <span class="c1"># Create and save the BM25 model from the tokenized documents</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>        <span class="n">tokenized_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">chunk</span><span class="o">.</span><span class="n">tokens</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>        <span class="n">bm25</span> <span class="o">=</span> <span class="n">BM25Okapi</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>        <span class="c1"># Save the tokenized documents and model to disk</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;documents.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;data.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">bm25</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span> <span class="n">BM25Okapi</span><span class="p">]:</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a><span class="sd">        Loads a BM25 model and tokenized documents from disk.</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a><span class="sd">        Args:</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a><span class="sd">        - `project_name (str)`: The name of the project.</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a><span class="sd">        - `model_name (str)`: The name of the model.</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a><span class="sd">        Returns:</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a><span class="sd">        - Tuple[List[TokenizedChunk], BM25Okapi]: The tokenized documents and the BM25 model.</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a><span class="sd">        Usage:</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a><span class="sd">        - `tokenized_docs, bm25 = bm25.load_model(&quot;project&quot;, &quot;model&quot;)`</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a>        <span class="c1"># Load the tokenized documents and BM25 model from disk</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;./.OsireRAG&quot;</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>        <span class="c1"># Load the documents</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;documents.pkl&quot;</span><span class="p">)),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a>            <span class="n">tokenized_documents</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a>        <span class="c1"># Load the BM25 model</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">)),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a>            <span class="n">index</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a>        <span class="k">return</span> <span class="n">tokenized_documents</span><span class="p">,</span> <span class="n">index</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a>    <span class="k">def</span> <span class="nf">search</span><span class="p">(</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>        <span class="n">tokenized_query</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">BM25Okapi</span><span class="p">,</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a>        <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a>        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Chunk</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a><span class="sd">        Performs a BM25 search on a tokenized query.</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a><span class="sd">        Args:</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a><span class="sd">        - `tokenized_query (List[str])`: The tokenized query.</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a><span class="sd">        - `model (BM25Okapi)`: The BM25 model to use for searching.</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a><span class="sd">        - `chunks (List[TokenizedChunk])`: The list of tokenized document chunks.</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a><span class="sd">        - `k (int)`: The number of top results to return.</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a><span class="sd">        Returns:</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a><span class="sd">        - List[Tuple[Chunk, float]]: A list of document chunks and their scores.</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a><span class="sd">        Usage:</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a><span class="sd">        - `results = bm25.search(tokenized_query, bm25_model, tokenized_chunks, k=10)`</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>        <span class="c1"># Perform the BM25 search</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_scores</span><span class="p">(</span><span class="n">tokenized_query</span><span class="p">)</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a>        <span class="c1"># Sort the chunks by score and return the top k results</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a>        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Chunk</span><span class="p">(</span><span class="o">**</span><span class="n">chunk</span><span class="o">.</span><span class="n">model_dump</span><span class="p">())</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a>        <span class="n">scored_docs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">scores</span><span class="p">)]</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a>        <span class="n">scored_docs</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>        <span class="k">return</span> <span class="n">scored_docs</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">k</span><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="TokenizedChunk">
                            <input id="TokenizedChunk-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">TokenizedChunk</span><wbr>(<span class="base"><a href="chunker.html#Chunk">app.core.models.chunker.Chunk</a></span>):

                <label class="view-source-button" for="TokenizedChunk-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TokenizedChunk"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TokenizedChunk-34"><a href="#TokenizedChunk-34"><span class="linenos">34</span></a><span class="k">class</span> <span class="nc">TokenizedChunk</span><span class="p">(</span><span class="n">Chunk</span><span class="p">):</span>
</span><span id="TokenizedChunk-35"><a href="#TokenizedChunk-35"><span class="linenos">35</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TokenizedChunk-36"><a href="#TokenizedChunk-36"><span class="linenos">36</span></a><span class="sd">    A Pydantic model for a chunk of text with tokenized content.</span>
</span><span id="TokenizedChunk-37"><a href="#TokenizedChunk-37"><span class="linenos">37</span></a>
</span><span id="TokenizedChunk-38"><a href="#TokenizedChunk-38"><span class="linenos">38</span></a><span class="sd">    Attributes:</span>
</span><span id="TokenizedChunk-39"><a href="#TokenizedChunk-39"><span class="linenos">39</span></a><span class="sd">    - tokens: List[str]: A list of tokens representing the tokenized content of the chunk.</span>
</span><span id="TokenizedChunk-40"><a href="#TokenizedChunk-40"><span class="linenos">40</span></a>
</span><span id="TokenizedChunk-41"><a href="#TokenizedChunk-41"><span class="linenos">41</span></a><span class="sd">    Usage:</span>
</span><span id="TokenizedChunk-42"><a href="#TokenizedChunk-42"><span class="linenos">42</span></a><span class="sd">    - Use this class to represent a text chunk after tokenization.</span>
</span><span id="TokenizedChunk-43"><a href="#TokenizedChunk-43"><span class="linenos">43</span></a>
</span><span id="TokenizedChunk-44"><a href="#TokenizedChunk-44"><span class="linenos">44</span></a><span class="sd">    Author: Adam Haile  </span>
</span><span id="TokenizedChunk-45"><a href="#TokenizedChunk-45"><span class="linenos">45</span></a><span class="sd">    Date: 10/23/2024</span>
</span><span id="TokenizedChunk-46"><a href="#TokenizedChunk-46"><span class="linenos">46</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="TokenizedChunk-47"><a href="#TokenizedChunk-47"><span class="linenos">47</span></a>
</span><span id="TokenizedChunk-48"><a href="#TokenizedChunk-48"><span class="linenos">48</span></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>A Pydantic model for a chunk of text with tokenized content.</p>

<p>Attributes:</p>

<ul>
<li>tokens: List[str]: A list of tokens representing the tokenized content of the chunk.</li>
</ul>

<p>Usage:</p>

<ul>
<li>Use this class to represent a text chunk after tokenization.</li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            <div id="TokenizedChunk.tokens" class="classattr">
                                <div class="attr variable">
            <span class="name">tokens</span><span class="annotation">: List[str]</span>

        
    </div>
    <a class="headerlink" href="#TokenizedChunk.tokens"></a>
    
    

                            </div>
                            <div id="TokenizedChunk.model_config" class="classattr">
                                <div class="attr variable">
            <span class="name">model_config</span><span class="annotation">: ClassVar[pydantic.config.ConfigDict]</span>        =
<span class="default_value">{}</span>

        
    </div>
    <a class="headerlink" href="#TokenizedChunk.model_config"></a>
    
            <div class="docstring"><p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="chunker.html#Chunk">app.core.models.chunker.Chunk</a></dt>
                                <dd id="TokenizedChunk.content" class="variable"><a href="chunker.html#Chunk.content">content</a></dd>
                <dd id="TokenizedChunk.index" class="variable"><a href="chunker.html#Chunk.index">index</a></dd>
                <dd id="TokenizedChunk.metadata" class="variable"><a href="chunker.html#Chunk.metadata">metadata</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ChunkTokenizer">
                            <input id="ChunkTokenizer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ChunkTokenizer</span><wbr>(<span class="base">pydantic.main.BaseModel</span>):

                <label class="view-source-button" for="ChunkTokenizer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ChunkTokenizer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ChunkTokenizer-51"><a href="#ChunkTokenizer-51"><span class="linenos"> 51</span></a><span class="k">class</span> <span class="nc">ChunkTokenizer</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="ChunkTokenizer-52"><a href="#ChunkTokenizer-52"><span class="linenos"> 52</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-53"><a href="#ChunkTokenizer-53"><span class="linenos"> 53</span></a><span class="sd">    A Pydantic model for tokenizing queries and document chunks.</span>
</span><span id="ChunkTokenizer-54"><a href="#ChunkTokenizer-54"><span class="linenos"> 54</span></a>
</span><span id="ChunkTokenizer-55"><a href="#ChunkTokenizer-55"><span class="linenos"> 55</span></a><span class="sd">    Attributes:</span>
</span><span id="ChunkTokenizer-56"><a href="#ChunkTokenizer-56"><span class="linenos"> 56</span></a><span class="sd">    - stop_words: set: A set of stop words to exclude during tokenization.</span>
</span><span id="ChunkTokenizer-57"><a href="#ChunkTokenizer-57"><span class="linenos"> 57</span></a><span class="sd">    - lemmatizer: Any: A WordNetLemmatizer instance for lemmatizing tokens.</span>
</span><span id="ChunkTokenizer-58"><a href="#ChunkTokenizer-58"><span class="linenos"> 58</span></a>
</span><span id="ChunkTokenizer-59"><a href="#ChunkTokenizer-59"><span class="linenos"> 59</span></a><span class="sd">    Methods:</span>
</span><span id="ChunkTokenizer-60"><a href="#ChunkTokenizer-60"><span class="linenos"> 60</span></a><span class="sd">    - tokenize_query: Tokenizes and lemmatizes a query string.</span>
</span><span id="ChunkTokenizer-61"><a href="#ChunkTokenizer-61"><span class="linenos"> 61</span></a><span class="sd">    - tokenize_documents: Tokenizes and lemmatizes the content of document chunks.</span>
</span><span id="ChunkTokenizer-62"><a href="#ChunkTokenizer-62"><span class="linenos"> 62</span></a>
</span><span id="ChunkTokenizer-63"><a href="#ChunkTokenizer-63"><span class="linenos"> 63</span></a><span class="sd">    Usage:</span>
</span><span id="ChunkTokenizer-64"><a href="#ChunkTokenizer-64"><span class="linenos"> 64</span></a><span class="sd">    - Instantiate this class to tokenize queries and document chunks for BM25.</span>
</span><span id="ChunkTokenizer-65"><a href="#ChunkTokenizer-65"><span class="linenos"> 65</span></a>
</span><span id="ChunkTokenizer-66"><a href="#ChunkTokenizer-66"><span class="linenos"> 66</span></a><span class="sd">    Author: Adam Haile  </span>
</span><span id="ChunkTokenizer-67"><a href="#ChunkTokenizer-67"><span class="linenos"> 67</span></a><span class="sd">    Date: 10/23/2024</span>
</span><span id="ChunkTokenizer-68"><a href="#ChunkTokenizer-68"><span class="linenos"> 68</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-69"><a href="#ChunkTokenizer-69"><span class="linenos"> 69</span></a>
</span><span id="ChunkTokenizer-70"><a href="#ChunkTokenizer-70"><span class="linenos"> 70</span></a>    <span class="n">stop_words</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="nb">set</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">))</span>
</span><span id="ChunkTokenizer-71"><a href="#ChunkTokenizer-71"><span class="linenos"> 71</span></a>    <span class="n">lemmatizer</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="n">WordNetLemmatizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
</span><span id="ChunkTokenizer-72"><a href="#ChunkTokenizer-72"><span class="linenos"> 72</span></a>
</span><span id="ChunkTokenizer-73"><a href="#ChunkTokenizer-73"><span class="linenos"> 73</span></a>    <span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
</span><span id="ChunkTokenizer-74"><a href="#ChunkTokenizer-74"><span class="linenos"> 74</span></a>        <span class="n">arbitrary_types_allowed</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ChunkTokenizer-75"><a href="#ChunkTokenizer-75"><span class="linenos"> 75</span></a>
</span><span id="ChunkTokenizer-76"><a href="#ChunkTokenizer-76"><span class="linenos"> 76</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ChunkTokenizer-77"><a href="#ChunkTokenizer-77"><span class="linenos"> 77</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-78"><a href="#ChunkTokenizer-78"><span class="linenos"> 78</span></a><span class="sd">        Initializes the tokenizer with custom NLTK data path.</span>
</span><span id="ChunkTokenizer-79"><a href="#ChunkTokenizer-79"><span class="linenos"> 79</span></a>
</span><span id="ChunkTokenizer-80"><a href="#ChunkTokenizer-80"><span class="linenos"> 80</span></a><span class="sd">        Raises:</span>
</span><span id="ChunkTokenizer-81"><a href="#ChunkTokenizer-81"><span class="linenos"> 81</span></a><span class="sd">        - None</span>
</span><span id="ChunkTokenizer-82"><a href="#ChunkTokenizer-82"><span class="linenos"> 82</span></a>
</span><span id="ChunkTokenizer-83"><a href="#ChunkTokenizer-83"><span class="linenos"> 83</span></a><span class="sd">        Usage:</span>
</span><span id="ChunkTokenizer-84"><a href="#ChunkTokenizer-84"><span class="linenos"> 84</span></a><span class="sd">        - tokenizer = ChunkTokenizer()</span>
</span><span id="ChunkTokenizer-85"><a href="#ChunkTokenizer-85"><span class="linenos"> 85</span></a>
</span><span id="ChunkTokenizer-86"><a href="#ChunkTokenizer-86"><span class="linenos"> 86</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="ChunkTokenizer-87"><a href="#ChunkTokenizer-87"><span class="linenos"> 87</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="ChunkTokenizer-88"><a href="#ChunkTokenizer-88"><span class="linenos"> 88</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-89"><a href="#ChunkTokenizer-89"><span class="linenos"> 89</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ChunkTokenizer-90"><a href="#ChunkTokenizer-90"><span class="linenos"> 90</span></a>        <span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;./nltk_data&quot;</span><span class="p">))</span>
</span><span id="ChunkTokenizer-91"><a href="#ChunkTokenizer-91"><span class="linenos"> 91</span></a>
</span><span id="ChunkTokenizer-92"><a href="#ChunkTokenizer-92"><span class="linenos"> 92</span></a>    <span class="k">def</span> <span class="nf">tokenize_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="ChunkTokenizer-93"><a href="#ChunkTokenizer-93"><span class="linenos"> 93</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-94"><a href="#ChunkTokenizer-94"><span class="linenos"> 94</span></a><span class="sd">        Tokenizes and lemmatizes a query string.</span>
</span><span id="ChunkTokenizer-95"><a href="#ChunkTokenizer-95"><span class="linenos"> 95</span></a>
</span><span id="ChunkTokenizer-96"><a href="#ChunkTokenizer-96"><span class="linenos"> 96</span></a><span class="sd">        Args:</span>
</span><span id="ChunkTokenizer-97"><a href="#ChunkTokenizer-97"><span class="linenos"> 97</span></a><span class="sd">        - `query (str)`: The query to tokenize.</span>
</span><span id="ChunkTokenizer-98"><a href="#ChunkTokenizer-98"><span class="linenos"> 98</span></a>
</span><span id="ChunkTokenizer-99"><a href="#ChunkTokenizer-99"><span class="linenos"> 99</span></a><span class="sd">        Returns:</span>
</span><span id="ChunkTokenizer-100"><a href="#ChunkTokenizer-100"><span class="linenos">100</span></a><span class="sd">        - List[str]: A list of lemmatized tokens from the query.</span>
</span><span id="ChunkTokenizer-101"><a href="#ChunkTokenizer-101"><span class="linenos">101</span></a>
</span><span id="ChunkTokenizer-102"><a href="#ChunkTokenizer-102"><span class="linenos">102</span></a><span class="sd">        Usage:</span>
</span><span id="ChunkTokenizer-103"><a href="#ChunkTokenizer-103"><span class="linenos">103</span></a><span class="sd">        - `tokens = tokenizer.tokenize_query(&quot;example query&quot;)`</span>
</span><span id="ChunkTokenizer-104"><a href="#ChunkTokenizer-104"><span class="linenos">104</span></a>
</span><span id="ChunkTokenizer-105"><a href="#ChunkTokenizer-105"><span class="linenos">105</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="ChunkTokenizer-106"><a href="#ChunkTokenizer-106"><span class="linenos">106</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="ChunkTokenizer-107"><a href="#ChunkTokenizer-107"><span class="linenos">107</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-108"><a href="#ChunkTokenizer-108"><span class="linenos">108</span></a>        <span class="c1"># Tokenize and lemmatize the query</span>
</span><span id="ChunkTokenizer-109"><a href="#ChunkTokenizer-109"><span class="linenos">109</span></a>        <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span id="ChunkTokenizer-110"><a href="#ChunkTokenizer-110"><span class="linenos">110</span></a>        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="ChunkTokenizer-111"><a href="#ChunkTokenizer-111"><span class="linenos">111</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="ChunkTokenizer-112"><a href="#ChunkTokenizer-112"><span class="linenos">112</span></a>            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span>
</span><span id="ChunkTokenizer-113"><a href="#ChunkTokenizer-113"><span class="linenos">113</span></a>            <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_words</span>
</span><span id="ChunkTokenizer-114"><a href="#ChunkTokenizer-114"><span class="linenos">114</span></a>        <span class="p">]</span>
</span><span id="ChunkTokenizer-115"><a href="#ChunkTokenizer-115"><span class="linenos">115</span></a>        <span class="k">return</span> <span class="n">tokens</span>
</span><span id="ChunkTokenizer-116"><a href="#ChunkTokenizer-116"><span class="linenos">116</span></a>
</span><span id="ChunkTokenizer-117"><a href="#ChunkTokenizer-117"><span class="linenos">117</span></a>    <span class="k">def</span> <span class="nf">tokenize_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Chunk</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">]:</span>
</span><span id="ChunkTokenizer-118"><a href="#ChunkTokenizer-118"><span class="linenos">118</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-119"><a href="#ChunkTokenizer-119"><span class="linenos">119</span></a><span class="sd">        Tokenizes and lemmatizes the content of document chunks.</span>
</span><span id="ChunkTokenizer-120"><a href="#ChunkTokenizer-120"><span class="linenos">120</span></a>
</span><span id="ChunkTokenizer-121"><a href="#ChunkTokenizer-121"><span class="linenos">121</span></a><span class="sd">        Args:</span>
</span><span id="ChunkTokenizer-122"><a href="#ChunkTokenizer-122"><span class="linenos">122</span></a><span class="sd">        - `chunks (List[Chunk])`: The list of document chunks to tokenize.</span>
</span><span id="ChunkTokenizer-123"><a href="#ChunkTokenizer-123"><span class="linenos">123</span></a>
</span><span id="ChunkTokenizer-124"><a href="#ChunkTokenizer-124"><span class="linenos">124</span></a><span class="sd">        Returns:</span>
</span><span id="ChunkTokenizer-125"><a href="#ChunkTokenizer-125"><span class="linenos">125</span></a><span class="sd">        - List[TokenizedChunk]: A list of TokenizedChunk objects.</span>
</span><span id="ChunkTokenizer-126"><a href="#ChunkTokenizer-126"><span class="linenos">126</span></a>
</span><span id="ChunkTokenizer-127"><a href="#ChunkTokenizer-127"><span class="linenos">127</span></a><span class="sd">        Usage:</span>
</span><span id="ChunkTokenizer-128"><a href="#ChunkTokenizer-128"><span class="linenos">128</span></a><span class="sd">        - `tokenized_chunks = tokenizer.tokenize_documents(chunks)`</span>
</span><span id="ChunkTokenizer-129"><a href="#ChunkTokenizer-129"><span class="linenos">129</span></a>
</span><span id="ChunkTokenizer-130"><a href="#ChunkTokenizer-130"><span class="linenos">130</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="ChunkTokenizer-131"><a href="#ChunkTokenizer-131"><span class="linenos">131</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="ChunkTokenizer-132"><a href="#ChunkTokenizer-132"><span class="linenos">132</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer-133"><a href="#ChunkTokenizer-133"><span class="linenos">133</span></a>        <span class="c1"># Tokenize and lemmatize the content of each chunk</span>
</span><span id="ChunkTokenizer-134"><a href="#ChunkTokenizer-134"><span class="linenos">134</span></a>        <span class="n">tokenized_docs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ChunkTokenizer-135"><a href="#ChunkTokenizer-135"><span class="linenos">135</span></a>        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
</span><span id="ChunkTokenizer-136"><a href="#ChunkTokenizer-136"><span class="linenos">136</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span id="ChunkTokenizer-137"><a href="#ChunkTokenizer-137"><span class="linenos">137</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="ChunkTokenizer-138"><a href="#ChunkTokenizer-138"><span class="linenos">138</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="ChunkTokenizer-139"><a href="#ChunkTokenizer-139"><span class="linenos">139</span></a>                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span>
</span><span id="ChunkTokenizer-140"><a href="#ChunkTokenizer-140"><span class="linenos">140</span></a>                <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_words</span>
</span><span id="ChunkTokenizer-141"><a href="#ChunkTokenizer-141"><span class="linenos">141</span></a>            <span class="p">]</span>
</span><span id="ChunkTokenizer-142"><a href="#ChunkTokenizer-142"><span class="linenos">142</span></a>            <span class="c1"># Append the tokenized chunk to the list</span>
</span><span id="ChunkTokenizer-143"><a href="#ChunkTokenizer-143"><span class="linenos">143</span></a>            <span class="n">tokenized_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TokenizedChunk</span><span class="p">(</span><span class="n">tokens</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="o">**</span><span class="n">chunk</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()))</span>
</span><span id="ChunkTokenizer-144"><a href="#ChunkTokenizer-144"><span class="linenos">144</span></a>        <span class="k">return</span> <span class="n">tokenized_docs</span>
</span></pre></div>


            <div class="docstring"><p>A Pydantic model for tokenizing queries and document chunks.</p>

<p>Attributes:</p>

<ul>
<li>stop_words: set: A set of stop words to exclude during tokenization.</li>
<li>lemmatizer: Any: A WordNetLemmatizer instance for lemmatizing tokens.</li>
</ul>

<p>Methods:</p>

<ul>
<li>tokenize_query: Tokenizes and lemmatizes a query string.</li>
<li>tokenize_documents: Tokenizes and lemmatizes the content of document chunks.</li>
</ul>

<p>Usage:</p>

<ul>
<li>Instantiate this class to tokenize queries and document chunks for BM25.</li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            <div id="ChunkTokenizer.__init__" class="classattr">
                                        <input id="ChunkTokenizer.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ChunkTokenizer</span><span class="signature pdoc-code condensed">()</span>

                <label class="view-source-button" for="ChunkTokenizer.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ChunkTokenizer.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ChunkTokenizer.__init__-76"><a href="#ChunkTokenizer.__init__-76"><span class="linenos">76</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ChunkTokenizer.__init__-77"><a href="#ChunkTokenizer.__init__-77"><span class="linenos">77</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer.__init__-78"><a href="#ChunkTokenizer.__init__-78"><span class="linenos">78</span></a><span class="sd">        Initializes the tokenizer with custom NLTK data path.</span>
</span><span id="ChunkTokenizer.__init__-79"><a href="#ChunkTokenizer.__init__-79"><span class="linenos">79</span></a>
</span><span id="ChunkTokenizer.__init__-80"><a href="#ChunkTokenizer.__init__-80"><span class="linenos">80</span></a><span class="sd">        Raises:</span>
</span><span id="ChunkTokenizer.__init__-81"><a href="#ChunkTokenizer.__init__-81"><span class="linenos">81</span></a><span class="sd">        - None</span>
</span><span id="ChunkTokenizer.__init__-82"><a href="#ChunkTokenizer.__init__-82"><span class="linenos">82</span></a>
</span><span id="ChunkTokenizer.__init__-83"><a href="#ChunkTokenizer.__init__-83"><span class="linenos">83</span></a><span class="sd">        Usage:</span>
</span><span id="ChunkTokenizer.__init__-84"><a href="#ChunkTokenizer.__init__-84"><span class="linenos">84</span></a><span class="sd">        - tokenizer = ChunkTokenizer()</span>
</span><span id="ChunkTokenizer.__init__-85"><a href="#ChunkTokenizer.__init__-85"><span class="linenos">85</span></a>
</span><span id="ChunkTokenizer.__init__-86"><a href="#ChunkTokenizer.__init__-86"><span class="linenos">86</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="ChunkTokenizer.__init__-87"><a href="#ChunkTokenizer.__init__-87"><span class="linenos">87</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="ChunkTokenizer.__init__-88"><a href="#ChunkTokenizer.__init__-88"><span class="linenos">88</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer.__init__-89"><a href="#ChunkTokenizer.__init__-89"><span class="linenos">89</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="ChunkTokenizer.__init__-90"><a href="#ChunkTokenizer.__init__-90"><span class="linenos">90</span></a>        <span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;./nltk_data&quot;</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the tokenizer with custom NLTK data path.</p>

<p>Raises:</p>

<ul>
<li>None</li>
</ul>

<p>Usage:</p>

<ul>
<li>tokenizer = ChunkTokenizer()</li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            </div>
                            <div id="ChunkTokenizer.stop_words" class="classattr">
                                <div class="attr variable">
            <span class="name">stop_words</span><span class="annotation">: ClassVar[set]</span>        =
<input id="ChunkTokenizer.stop_words-view-value" class="view-value-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
            <label class="view-value-button pdoc-button" for="ChunkTokenizer.stop_words-view-value"></label><span class="default_value">{&#39;needn&#39;, &#39;once&#39;, &#39;she&#39;, &#39;what&#39;, &#39;only&#39;, &#39;re&#39;, &#39;have&#39;, &#39;too&#39;, &#39;himself&#39;, &#39;the&#39;, &#34;couldn&#39;t&#34;, &#39;against&#39;, &#39;as&#39;, &#34;mustn&#39;t&#34;, &#34;haven&#39;t&#34;, &#39;most&#39;, &#39;shan&#39;, &#39;further&#39;, &#39;before&#39;, &#39;any&#39;, &#39;is&#39;, &#39;m&#39;, &#34;needn&#39;t&#34;, &#39;are&#39;, &#39;our&#39;, &#39;yourself&#39;, &#39;its&#39;, &#39;been&#39;, &#39;over&#39;, &#39;can&#39;, &#39;isn&#39;, &#39;i&#39;, &#39;how&#39;, &#34;wasn&#39;t&#34;, &#39;you&#39;, &#39;by&#39;, &#39;down&#39;, &#39;below&#39;, &#39;themselves&#39;, &#39;if&#39;, &#39;a&#39;, &#39;which&#39;, &#39;that&#39;, &#39;did&#39;, &#39;hasn&#39;, &#39;shouldn&#39;, &#39;itself&#39;, &#39;some&#39;, &#34;you&#39;re&#34;, &#39;there&#39;, &#34;shan&#39;t&#34;, &#39;ve&#39;, &#39;mustn&#39;, &#39;in&#39;, &#34;hadn&#39;t&#34;, &#39;will&#39;, &#39;doing&#39;, &#39;while&#39;, &#39;those&#39;, &#39;herself&#39;, &#39;at&#39;, &#39;yours&#39;, &#39;hadn&#39;, &#39;during&#39;, &#39;above&#39;, &#39;had&#39;, &#39;am&#39;, &#34;aren&#39;t&#34;, &#34;hasn&#39;t&#34;, &#39;t&#39;, &#34;you&#39;ve&#34;, &#39;then&#39;, &#39;on&#39;, &#39;just&#39;, &#34;doesn&#39;t&#34;, &#39;where&#39;, &#39;because&#39;, &#39;y&#39;, &#39;same&#39;, &#39;when&#39;, &#39;such&#39;, &#39;were&#39;, &#39;own&#39;, &#39;or&#39;, &#39;through&#39;, &#34;that&#39;ll&#34;, &#39;has&#39;, &#39;should&#39;, &#39;him&#39;, &#39;with&#39;, &#34;shouldn&#39;t&#34;, &#39;being&#39;, &#39;he&#39;, &#39;wouldn&#39;, &#39;don&#39;, &#39;under&#39;, &#39;out&#39;, &#39;and&#39;, &#34;weren&#39;t&#34;, &#39;an&#39;, &#39;they&#39;, &#39;but&#39;, &#39;your&#39;, &#39;very&#39;, &#34;don&#39;t&#34;, &#39;these&#39;, &#39;this&#39;, &#34;didn&#39;t&#34;, &#39;haven&#39;, &#39;weren&#39;, &#39;no&#39;, &#39;into&#39;, &#39;myself&#39;, &#39;them&#39;, &#39;doesn&#39;, &#39;both&#39;, &#39;me&#39;, &#39;more&#39;, &#39;now&#39;, &#39;it&#39;, &#39;theirs&#39;, &#39;off&#39;, &#39;than&#39;, &#34;won&#39;t&#34;, &#34;she&#39;s&#34;, &#39;didn&#39;, &#39;her&#39;, &#39;couldn&#39;, &#39;for&#39;, &#39;my&#39;, &#39;nor&#39;, &#34;you&#39;d&#34;, &#39;to&#39;, &#39;won&#39;, &#39;yourselves&#39;, &#39;whom&#39;, &#39;here&#39;, &#39;ll&#39;, &#39;until&#39;, &#39;up&#39;, &#39;wasn&#39;, &#39;of&#39;, &#39;so&#39;, &#39;does&#39;, &#39;s&#39;, &#39;his&#39;, &#39;ourselves&#39;, &#34;should&#39;ve&#34;, &#39;about&#39;, &#34;you&#39;ll&#34;, &#39;from&#39;, &#39;other&#39;, &#39;having&#39;, &#39;we&#39;, &#39;ma&#39;, &#39;why&#39;, &#39;not&#39;, &#34;wouldn&#39;t&#34;, &#39;between&#39;, &#39;again&#39;, &#39;was&#39;, &#39;all&#39;, &#39;few&#39;, &#34;isn&#39;t&#34;, &#39;do&#39;, &#39;hers&#39;, &#39;be&#39;, &#39;ain&#39;, &#39;o&#39;, &#39;mightn&#39;, &#39;who&#39;, &#39;each&#39;, &#39;ours&#39;, &#39;their&#39;, &#39;after&#39;, &#39;d&#39;, &#34;mightn&#39;t&#34;, &#39;aren&#39;, &#34;it&#39;s&#34;}</span>

        
    </div>
    <a class="headerlink" href="#ChunkTokenizer.stop_words"></a>
    
    

                            </div>
                            <div id="ChunkTokenizer.lemmatizer" class="classattr">
                                <div class="attr variable">
            <span class="name">lemmatizer</span><span class="annotation">: ClassVar[nltk.stem.wordnet.WordNetLemmatizer]</span>        =
<span class="default_value">&lt;WordNetLemmatizer&gt;</span>

        
    </div>
    <a class="headerlink" href="#ChunkTokenizer.lemmatizer"></a>
    
    

                            </div>
                            <div id="ChunkTokenizer.tokenize_query" class="classattr">
                                        <input id="ChunkTokenizer.tokenize_query-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">tokenize_query</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">query</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="ChunkTokenizer.tokenize_query-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ChunkTokenizer.tokenize_query"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ChunkTokenizer.tokenize_query-92"><a href="#ChunkTokenizer.tokenize_query-92"><span class="linenos"> 92</span></a>    <span class="k">def</span> <span class="nf">tokenize_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="ChunkTokenizer.tokenize_query-93"><a href="#ChunkTokenizer.tokenize_query-93"><span class="linenos"> 93</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer.tokenize_query-94"><a href="#ChunkTokenizer.tokenize_query-94"><span class="linenos"> 94</span></a><span class="sd">        Tokenizes and lemmatizes a query string.</span>
</span><span id="ChunkTokenizer.tokenize_query-95"><a href="#ChunkTokenizer.tokenize_query-95"><span class="linenos"> 95</span></a>
</span><span id="ChunkTokenizer.tokenize_query-96"><a href="#ChunkTokenizer.tokenize_query-96"><span class="linenos"> 96</span></a><span class="sd">        Args:</span>
</span><span id="ChunkTokenizer.tokenize_query-97"><a href="#ChunkTokenizer.tokenize_query-97"><span class="linenos"> 97</span></a><span class="sd">        - `query (str)`: The query to tokenize.</span>
</span><span id="ChunkTokenizer.tokenize_query-98"><a href="#ChunkTokenizer.tokenize_query-98"><span class="linenos"> 98</span></a>
</span><span id="ChunkTokenizer.tokenize_query-99"><a href="#ChunkTokenizer.tokenize_query-99"><span class="linenos"> 99</span></a><span class="sd">        Returns:</span>
</span><span id="ChunkTokenizer.tokenize_query-100"><a href="#ChunkTokenizer.tokenize_query-100"><span class="linenos">100</span></a><span class="sd">        - List[str]: A list of lemmatized tokens from the query.</span>
</span><span id="ChunkTokenizer.tokenize_query-101"><a href="#ChunkTokenizer.tokenize_query-101"><span class="linenos">101</span></a>
</span><span id="ChunkTokenizer.tokenize_query-102"><a href="#ChunkTokenizer.tokenize_query-102"><span class="linenos">102</span></a><span class="sd">        Usage:</span>
</span><span id="ChunkTokenizer.tokenize_query-103"><a href="#ChunkTokenizer.tokenize_query-103"><span class="linenos">103</span></a><span class="sd">        - `tokens = tokenizer.tokenize_query(&quot;example query&quot;)`</span>
</span><span id="ChunkTokenizer.tokenize_query-104"><a href="#ChunkTokenizer.tokenize_query-104"><span class="linenos">104</span></a>
</span><span id="ChunkTokenizer.tokenize_query-105"><a href="#ChunkTokenizer.tokenize_query-105"><span class="linenos">105</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="ChunkTokenizer.tokenize_query-106"><a href="#ChunkTokenizer.tokenize_query-106"><span class="linenos">106</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="ChunkTokenizer.tokenize_query-107"><a href="#ChunkTokenizer.tokenize_query-107"><span class="linenos">107</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer.tokenize_query-108"><a href="#ChunkTokenizer.tokenize_query-108"><span class="linenos">108</span></a>        <span class="c1"># Tokenize and lemmatize the query</span>
</span><span id="ChunkTokenizer.tokenize_query-109"><a href="#ChunkTokenizer.tokenize_query-109"><span class="linenos">109</span></a>        <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span id="ChunkTokenizer.tokenize_query-110"><a href="#ChunkTokenizer.tokenize_query-110"><span class="linenos">110</span></a>        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="ChunkTokenizer.tokenize_query-111"><a href="#ChunkTokenizer.tokenize_query-111"><span class="linenos">111</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="ChunkTokenizer.tokenize_query-112"><a href="#ChunkTokenizer.tokenize_query-112"><span class="linenos">112</span></a>            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span>
</span><span id="ChunkTokenizer.tokenize_query-113"><a href="#ChunkTokenizer.tokenize_query-113"><span class="linenos">113</span></a>            <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_words</span>
</span><span id="ChunkTokenizer.tokenize_query-114"><a href="#ChunkTokenizer.tokenize_query-114"><span class="linenos">114</span></a>        <span class="p">]</span>
</span><span id="ChunkTokenizer.tokenize_query-115"><a href="#ChunkTokenizer.tokenize_query-115"><span class="linenos">115</span></a>        <span class="k">return</span> <span class="n">tokens</span>
</span></pre></div>


            <div class="docstring"><p>Tokenizes and lemmatizes a query string.</p>

<p>Args:</p>

<ul>
<li><code>query (str)</code>: The query to tokenize.</li>
</ul>

<p>Returns:</p>

<ul>
<li>List[str]: A list of lemmatized tokens from the query.</li>
</ul>

<p>Usage:</p>

<ul>
<li><code>tokens = tokenizer.tokenize_query("example query")</code></li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            </div>
                            <div id="ChunkTokenizer.tokenize_documents" class="classattr">
                                        <input id="ChunkTokenizer.tokenize_documents-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">tokenize_documents</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n"><a href="chunker.html#Chunk">app.core.models.chunker.Chunk</a></span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="n"><a href="#TokenizedChunk">TokenizedChunk</a></span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="ChunkTokenizer.tokenize_documents-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ChunkTokenizer.tokenize_documents"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ChunkTokenizer.tokenize_documents-117"><a href="#ChunkTokenizer.tokenize_documents-117"><span class="linenos">117</span></a>    <span class="k">def</span> <span class="nf">tokenize_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Chunk</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">]:</span>
</span><span id="ChunkTokenizer.tokenize_documents-118"><a href="#ChunkTokenizer.tokenize_documents-118"><span class="linenos">118</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer.tokenize_documents-119"><a href="#ChunkTokenizer.tokenize_documents-119"><span class="linenos">119</span></a><span class="sd">        Tokenizes and lemmatizes the content of document chunks.</span>
</span><span id="ChunkTokenizer.tokenize_documents-120"><a href="#ChunkTokenizer.tokenize_documents-120"><span class="linenos">120</span></a>
</span><span id="ChunkTokenizer.tokenize_documents-121"><a href="#ChunkTokenizer.tokenize_documents-121"><span class="linenos">121</span></a><span class="sd">        Args:</span>
</span><span id="ChunkTokenizer.tokenize_documents-122"><a href="#ChunkTokenizer.tokenize_documents-122"><span class="linenos">122</span></a><span class="sd">        - `chunks (List[Chunk])`: The list of document chunks to tokenize.</span>
</span><span id="ChunkTokenizer.tokenize_documents-123"><a href="#ChunkTokenizer.tokenize_documents-123"><span class="linenos">123</span></a>
</span><span id="ChunkTokenizer.tokenize_documents-124"><a href="#ChunkTokenizer.tokenize_documents-124"><span class="linenos">124</span></a><span class="sd">        Returns:</span>
</span><span id="ChunkTokenizer.tokenize_documents-125"><a href="#ChunkTokenizer.tokenize_documents-125"><span class="linenos">125</span></a><span class="sd">        - List[TokenizedChunk]: A list of TokenizedChunk objects.</span>
</span><span id="ChunkTokenizer.tokenize_documents-126"><a href="#ChunkTokenizer.tokenize_documents-126"><span class="linenos">126</span></a>
</span><span id="ChunkTokenizer.tokenize_documents-127"><a href="#ChunkTokenizer.tokenize_documents-127"><span class="linenos">127</span></a><span class="sd">        Usage:</span>
</span><span id="ChunkTokenizer.tokenize_documents-128"><a href="#ChunkTokenizer.tokenize_documents-128"><span class="linenos">128</span></a><span class="sd">        - `tokenized_chunks = tokenizer.tokenize_documents(chunks)`</span>
</span><span id="ChunkTokenizer.tokenize_documents-129"><a href="#ChunkTokenizer.tokenize_documents-129"><span class="linenos">129</span></a>
</span><span id="ChunkTokenizer.tokenize_documents-130"><a href="#ChunkTokenizer.tokenize_documents-130"><span class="linenos">130</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="ChunkTokenizer.tokenize_documents-131"><a href="#ChunkTokenizer.tokenize_documents-131"><span class="linenos">131</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="ChunkTokenizer.tokenize_documents-132"><a href="#ChunkTokenizer.tokenize_documents-132"><span class="linenos">132</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ChunkTokenizer.tokenize_documents-133"><a href="#ChunkTokenizer.tokenize_documents-133"><span class="linenos">133</span></a>        <span class="c1"># Tokenize and lemmatize the content of each chunk</span>
</span><span id="ChunkTokenizer.tokenize_documents-134"><a href="#ChunkTokenizer.tokenize_documents-134"><span class="linenos">134</span></a>        <span class="n">tokenized_docs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ChunkTokenizer.tokenize_documents-135"><a href="#ChunkTokenizer.tokenize_documents-135"><span class="linenos">135</span></a>        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
</span><span id="ChunkTokenizer.tokenize_documents-136"><a href="#ChunkTokenizer.tokenize_documents-136"><span class="linenos">136</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span id="ChunkTokenizer.tokenize_documents-137"><a href="#ChunkTokenizer.tokenize_documents-137"><span class="linenos">137</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="ChunkTokenizer.tokenize_documents-138"><a href="#ChunkTokenizer.tokenize_documents-138"><span class="linenos">138</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="ChunkTokenizer.tokenize_documents-139"><a href="#ChunkTokenizer.tokenize_documents-139"><span class="linenos">139</span></a>                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span>
</span><span id="ChunkTokenizer.tokenize_documents-140"><a href="#ChunkTokenizer.tokenize_documents-140"><span class="linenos">140</span></a>                <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_words</span>
</span><span id="ChunkTokenizer.tokenize_documents-141"><a href="#ChunkTokenizer.tokenize_documents-141"><span class="linenos">141</span></a>            <span class="p">]</span>
</span><span id="ChunkTokenizer.tokenize_documents-142"><a href="#ChunkTokenizer.tokenize_documents-142"><span class="linenos">142</span></a>            <span class="c1"># Append the tokenized chunk to the list</span>
</span><span id="ChunkTokenizer.tokenize_documents-143"><a href="#ChunkTokenizer.tokenize_documents-143"><span class="linenos">143</span></a>            <span class="n">tokenized_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TokenizedChunk</span><span class="p">(</span><span class="n">tokens</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="o">**</span><span class="n">chunk</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()))</span>
</span><span id="ChunkTokenizer.tokenize_documents-144"><a href="#ChunkTokenizer.tokenize_documents-144"><span class="linenos">144</span></a>        <span class="k">return</span> <span class="n">tokenized_docs</span>
</span></pre></div>


            <div class="docstring"><p>Tokenizes and lemmatizes the content of document chunks.</p>

<p>Args:</p>

<ul>
<li><code>chunks (List[Chunk])</code>: The list of document chunks to tokenize.</li>
</ul>

<p>Returns:</p>

<ul>
<li>List[TokenizedChunk]: A list of TokenizedChunk objects.</li>
</ul>

<p>Usage:</p>

<ul>
<li><code>tokenized_chunks = tokenizer.tokenize_documents(chunks)</code></li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            </div>
                            <div id="ChunkTokenizer.model_config" class="classattr">
                                <div class="attr variable">
            <span class="name">model_config</span><span class="annotation">: ClassVar[pydantic.config.ConfigDict]</span>        =
<span class="default_value">{&#39;arbitrary_types_allowed&#39;: True}</span>

        
    </div>
    <a class="headerlink" href="#ChunkTokenizer.model_config"></a>
    
            <div class="docstring"><p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>
</div>


                            </div>
                </section>
                <section id="ChunkTokenizer.Config">
                            <input id="ChunkTokenizer.Config-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ChunkTokenizer.Config</span>:

                <label class="view-source-button" for="ChunkTokenizer.Config-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ChunkTokenizer.Config"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ChunkTokenizer.Config-73"><a href="#ChunkTokenizer.Config-73"><span class="linenos">73</span></a>    <span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
</span><span id="ChunkTokenizer.Config-74"><a href="#ChunkTokenizer.Config-74"><span class="linenos">74</span></a>        <span class="n">arbitrary_types_allowed</span> <span class="o">=</span> <span class="kc">True</span>
</span></pre></div>


    

                            <div id="ChunkTokenizer.Config.arbitrary_types_allowed" class="classattr">
                                <div class="attr variable">
            <span class="name">arbitrary_types_allowed</span>        =
<span class="default_value">True</span>

        
    </div>
    <a class="headerlink" href="#ChunkTokenizer.Config.arbitrary_types_allowed"></a>
    
    

                            </div>
                </section>
                <section id="BM25Model">
                            <input id="BM25Model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">BM25Model</span><wbr>(<span class="base">pydantic.main.BaseModel</span>):

                <label class="view-source-button" for="BM25Model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BM25Model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BM25Model-147"><a href="#BM25Model-147"><span class="linenos">147</span></a><span class="k">class</span> <span class="nc">BM25Model</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="BM25Model-148"><a href="#BM25Model-148"><span class="linenos">148</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BM25Model-149"><a href="#BM25Model-149"><span class="linenos">149</span></a><span class="sd">    A Pydantic model for creating, loading, and searching BM25 indices.</span>
</span><span id="BM25Model-150"><a href="#BM25Model-150"><span class="linenos">150</span></a>
</span><span id="BM25Model-151"><a href="#BM25Model-151"><span class="linenos">151</span></a><span class="sd">    Methods:</span>
</span><span id="BM25Model-152"><a href="#BM25Model-152"><span class="linenos">152</span></a><span class="sd">    - create_model: Creates and saves a BM25 model for a set of tokenized document chunks.</span>
</span><span id="BM25Model-153"><a href="#BM25Model-153"><span class="linenos">153</span></a><span class="sd">    - load_model: Loads a BM25 model and tokenized documents from disk.</span>
</span><span id="BM25Model-154"><a href="#BM25Model-154"><span class="linenos">154</span></a><span class="sd">    - search: Performs a BM25 search on a tokenized query.</span>
</span><span id="BM25Model-155"><a href="#BM25Model-155"><span class="linenos">155</span></a>
</span><span id="BM25Model-156"><a href="#BM25Model-156"><span class="linenos">156</span></a><span class="sd">    Usage:</span>
</span><span id="BM25Model-157"><a href="#BM25Model-157"><span class="linenos">157</span></a><span class="sd">    - Instantiate this class to create, load, and search BM25 indices.</span>
</span><span id="BM25Model-158"><a href="#BM25Model-158"><span class="linenos">158</span></a>
</span><span id="BM25Model-159"><a href="#BM25Model-159"><span class="linenos">159</span></a><span class="sd">    Author: Adam Haile  </span>
</span><span id="BM25Model-160"><a href="#BM25Model-160"><span class="linenos">160</span></a><span class="sd">    Date: 10/23/2024</span>
</span><span id="BM25Model-161"><a href="#BM25Model-161"><span class="linenos">161</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="BM25Model-162"><a href="#BM25Model-162"><span class="linenos">162</span></a>
</span><span id="BM25Model-163"><a href="#BM25Model-163"><span class="linenos">163</span></a>    <span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span>
</span><span id="BM25Model-164"><a href="#BM25Model-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="BM25Model-165"><a href="#BM25Model-165"><span class="linenos">165</span></a>    <span class="p">):</span>
</span><span id="BM25Model-166"><a href="#BM25Model-166"><span class="linenos">166</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BM25Model-167"><a href="#BM25Model-167"><span class="linenos">167</span></a><span class="sd">        Creates and saves a BM25 model for a set of tokenized document chunks.</span>
</span><span id="BM25Model-168"><a href="#BM25Model-168"><span class="linenos">168</span></a>
</span><span id="BM25Model-169"><a href="#BM25Model-169"><span class="linenos">169</span></a><span class="sd">        Args:</span>
</span><span id="BM25Model-170"><a href="#BM25Model-170"><span class="linenos">170</span></a><span class="sd">        - `project_name (str)`: The name of the project.</span>
</span><span id="BM25Model-171"><a href="#BM25Model-171"><span class="linenos">171</span></a><span class="sd">        - `model_name (str)`: The name of the model.</span>
</span><span id="BM25Model-172"><a href="#BM25Model-172"><span class="linenos">172</span></a><span class="sd">        - `chunks (List[TokenizedChunk])`: The list of tokenized document chunks.</span>
</span><span id="BM25Model-173"><a href="#BM25Model-173"><span class="linenos">173</span></a><span class="sd">        - `kwargs (Dict[Any, Any])`: Additional arguments for BM25Okapi.</span>
</span><span id="BM25Model-174"><a href="#BM25Model-174"><span class="linenos">174</span></a>
</span><span id="BM25Model-175"><a href="#BM25Model-175"><span class="linenos">175</span></a><span class="sd">        Returns:</span>
</span><span id="BM25Model-176"><a href="#BM25Model-176"><span class="linenos">176</span></a><span class="sd">        - None</span>
</span><span id="BM25Model-177"><a href="#BM25Model-177"><span class="linenos">177</span></a>
</span><span id="BM25Model-178"><a href="#BM25Model-178"><span class="linenos">178</span></a><span class="sd">        Raises:</span>
</span><span id="BM25Model-179"><a href="#BM25Model-179"><span class="linenos">179</span></a><span class="sd">        - FileExistsError: If the model directory already exists.</span>
</span><span id="BM25Model-180"><a href="#BM25Model-180"><span class="linenos">180</span></a>
</span><span id="BM25Model-181"><a href="#BM25Model-181"><span class="linenos">181</span></a><span class="sd">        Usage:</span>
</span><span id="BM25Model-182"><a href="#BM25Model-182"><span class="linenos">182</span></a><span class="sd">        - `bm25.create_model(&quot;project&quot;, &quot;model&quot;, tokenized_chunks)`</span>
</span><span id="BM25Model-183"><a href="#BM25Model-183"><span class="linenos">183</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BM25Model-184"><a href="#BM25Model-184"><span class="linenos">184</span></a>        <span class="c1"># Create the model directory if it does not exist</span>
</span><span id="BM25Model-185"><a href="#BM25Model-185"><span class="linenos">185</span></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;./.OsireRAG&quot;</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span><span id="BM25Model-186"><a href="#BM25Model-186"><span class="linenos">186</span></a>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BM25Model-187"><a href="#BM25Model-187"><span class="linenos">187</span></a>
</span><span id="BM25Model-188"><a href="#BM25Model-188"><span class="linenos">188</span></a>        <span class="c1"># Create and save the BM25 model from the tokenized documents</span>
</span><span id="BM25Model-189"><a href="#BM25Model-189"><span class="linenos">189</span></a>        <span class="n">tokenized_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">chunk</span><span class="o">.</span><span class="n">tokens</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
</span><span id="BM25Model-190"><a href="#BM25Model-190"><span class="linenos">190</span></a>        <span class="n">bm25</span> <span class="o">=</span> <span class="n">BM25Okapi</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="BM25Model-191"><a href="#BM25Model-191"><span class="linenos">191</span></a>
</span><span id="BM25Model-192"><a href="#BM25Model-192"><span class="linenos">192</span></a>        <span class="c1"># Save the tokenized documents and model to disk</span>
</span><span id="BM25Model-193"><a href="#BM25Model-193"><span class="linenos">193</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;documents.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model-194"><a href="#BM25Model-194"><span class="linenos">194</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model-195"><a href="#BM25Model-195"><span class="linenos">195</span></a>
</span><span id="BM25Model-196"><a href="#BM25Model-196"><span class="linenos">196</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;data.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model-197"><a href="#BM25Model-197"><span class="linenos">197</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model-198"><a href="#BM25Model-198"><span class="linenos">198</span></a>
</span><span id="BM25Model-199"><a href="#BM25Model-199"><span class="linenos">199</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model-200"><a href="#BM25Model-200"><span class="linenos">200</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">bm25</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model-201"><a href="#BM25Model-201"><span class="linenos">201</span></a>
</span><span id="BM25Model-202"><a href="#BM25Model-202"><span class="linenos">202</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span>
</span><span id="BM25Model-203"><a href="#BM25Model-203"><span class="linenos">203</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="BM25Model-204"><a href="#BM25Model-204"><span class="linenos">204</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span> <span class="n">BM25Okapi</span><span class="p">]:</span>
</span><span id="BM25Model-205"><a href="#BM25Model-205"><span class="linenos">205</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BM25Model-206"><a href="#BM25Model-206"><span class="linenos">206</span></a><span class="sd">        Loads a BM25 model and tokenized documents from disk.</span>
</span><span id="BM25Model-207"><a href="#BM25Model-207"><span class="linenos">207</span></a>
</span><span id="BM25Model-208"><a href="#BM25Model-208"><span class="linenos">208</span></a><span class="sd">        Args:</span>
</span><span id="BM25Model-209"><a href="#BM25Model-209"><span class="linenos">209</span></a><span class="sd">        - `project_name (str)`: The name of the project.</span>
</span><span id="BM25Model-210"><a href="#BM25Model-210"><span class="linenos">210</span></a><span class="sd">        - `model_name (str)`: The name of the model.</span>
</span><span id="BM25Model-211"><a href="#BM25Model-211"><span class="linenos">211</span></a>
</span><span id="BM25Model-212"><a href="#BM25Model-212"><span class="linenos">212</span></a><span class="sd">        Returns:</span>
</span><span id="BM25Model-213"><a href="#BM25Model-213"><span class="linenos">213</span></a><span class="sd">        - Tuple[List[TokenizedChunk], BM25Okapi]: The tokenized documents and the BM25 model.</span>
</span><span id="BM25Model-214"><a href="#BM25Model-214"><span class="linenos">214</span></a>
</span><span id="BM25Model-215"><a href="#BM25Model-215"><span class="linenos">215</span></a><span class="sd">        Usage:</span>
</span><span id="BM25Model-216"><a href="#BM25Model-216"><span class="linenos">216</span></a><span class="sd">        - `tokenized_docs, bm25 = bm25.load_model(&quot;project&quot;, &quot;model&quot;)`</span>
</span><span id="BM25Model-217"><a href="#BM25Model-217"><span class="linenos">217</span></a>
</span><span id="BM25Model-218"><a href="#BM25Model-218"><span class="linenos">218</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="BM25Model-219"><a href="#BM25Model-219"><span class="linenos">219</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="BM25Model-220"><a href="#BM25Model-220"><span class="linenos">220</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BM25Model-221"><a href="#BM25Model-221"><span class="linenos">221</span></a>        <span class="c1"># Load the tokenized documents and BM25 model from disk</span>
</span><span id="BM25Model-222"><a href="#BM25Model-222"><span class="linenos">222</span></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;./.OsireRAG&quot;</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span><span id="BM25Model-223"><a href="#BM25Model-223"><span class="linenos">223</span></a>
</span><span id="BM25Model-224"><a href="#BM25Model-224"><span class="linenos">224</span></a>        <span class="c1"># Load the documents</span>
</span><span id="BM25Model-225"><a href="#BM25Model-225"><span class="linenos">225</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;documents.pkl&quot;</span><span class="p">)),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model-226"><a href="#BM25Model-226"><span class="linenos">226</span></a>            <span class="n">tokenized_documents</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model-227"><a href="#BM25Model-227"><span class="linenos">227</span></a>
</span><span id="BM25Model-228"><a href="#BM25Model-228"><span class="linenos">228</span></a>        <span class="c1"># Load the BM25 model</span>
</span><span id="BM25Model-229"><a href="#BM25Model-229"><span class="linenos">229</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">)),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model-230"><a href="#BM25Model-230"><span class="linenos">230</span></a>            <span class="n">index</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model-231"><a href="#BM25Model-231"><span class="linenos">231</span></a>
</span><span id="BM25Model-232"><a href="#BM25Model-232"><span class="linenos">232</span></a>        <span class="k">return</span> <span class="n">tokenized_documents</span><span class="p">,</span> <span class="n">index</span>
</span><span id="BM25Model-233"><a href="#BM25Model-233"><span class="linenos">233</span></a>
</span><span id="BM25Model-234"><a href="#BM25Model-234"><span class="linenos">234</span></a>    <span class="k">def</span> <span class="nf">search</span><span class="p">(</span>
</span><span id="BM25Model-235"><a href="#BM25Model-235"><span class="linenos">235</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BM25Model-236"><a href="#BM25Model-236"><span class="linenos">236</span></a>        <span class="n">tokenized_query</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
</span><span id="BM25Model-237"><a href="#BM25Model-237"><span class="linenos">237</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">BM25Okapi</span><span class="p">,</span>
</span><span id="BM25Model-238"><a href="#BM25Model-238"><span class="linenos">238</span></a>        <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span>
</span><span id="BM25Model-239"><a href="#BM25Model-239"><span class="linenos">239</span></a>        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="BM25Model-240"><a href="#BM25Model-240"><span class="linenos">240</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Chunk</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
</span><span id="BM25Model-241"><a href="#BM25Model-241"><span class="linenos">241</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BM25Model-242"><a href="#BM25Model-242"><span class="linenos">242</span></a><span class="sd">        Performs a BM25 search on a tokenized query.</span>
</span><span id="BM25Model-243"><a href="#BM25Model-243"><span class="linenos">243</span></a>
</span><span id="BM25Model-244"><a href="#BM25Model-244"><span class="linenos">244</span></a><span class="sd">        Args:</span>
</span><span id="BM25Model-245"><a href="#BM25Model-245"><span class="linenos">245</span></a><span class="sd">        - `tokenized_query (List[str])`: The tokenized query.</span>
</span><span id="BM25Model-246"><a href="#BM25Model-246"><span class="linenos">246</span></a><span class="sd">        - `model (BM25Okapi)`: The BM25 model to use for searching.</span>
</span><span id="BM25Model-247"><a href="#BM25Model-247"><span class="linenos">247</span></a><span class="sd">        - `chunks (List[TokenizedChunk])`: The list of tokenized document chunks.</span>
</span><span id="BM25Model-248"><a href="#BM25Model-248"><span class="linenos">248</span></a><span class="sd">        - `k (int)`: The number of top results to return.</span>
</span><span id="BM25Model-249"><a href="#BM25Model-249"><span class="linenos">249</span></a>
</span><span id="BM25Model-250"><a href="#BM25Model-250"><span class="linenos">250</span></a><span class="sd">        Returns:</span>
</span><span id="BM25Model-251"><a href="#BM25Model-251"><span class="linenos">251</span></a><span class="sd">        - List[Tuple[Chunk, float]]: A list of document chunks and their scores.</span>
</span><span id="BM25Model-252"><a href="#BM25Model-252"><span class="linenos">252</span></a>
</span><span id="BM25Model-253"><a href="#BM25Model-253"><span class="linenos">253</span></a><span class="sd">        Usage:</span>
</span><span id="BM25Model-254"><a href="#BM25Model-254"><span class="linenos">254</span></a><span class="sd">        - `results = bm25.search(tokenized_query, bm25_model, tokenized_chunks, k=10)`</span>
</span><span id="BM25Model-255"><a href="#BM25Model-255"><span class="linenos">255</span></a>
</span><span id="BM25Model-256"><a href="#BM25Model-256"><span class="linenos">256</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="BM25Model-257"><a href="#BM25Model-257"><span class="linenos">257</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="BM25Model-258"><a href="#BM25Model-258"><span class="linenos">258</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BM25Model-259"><a href="#BM25Model-259"><span class="linenos">259</span></a>        <span class="c1"># Perform the BM25 search</span>
</span><span id="BM25Model-260"><a href="#BM25Model-260"><span class="linenos">260</span></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_scores</span><span class="p">(</span><span class="n">tokenized_query</span><span class="p">)</span>
</span><span id="BM25Model-261"><a href="#BM25Model-261"><span class="linenos">261</span></a>
</span><span id="BM25Model-262"><a href="#BM25Model-262"><span class="linenos">262</span></a>        <span class="c1"># Sort the chunks by score and return the top k results</span>
</span><span id="BM25Model-263"><a href="#BM25Model-263"><span class="linenos">263</span></a>        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Chunk</span><span class="p">(</span><span class="o">**</span><span class="n">chunk</span><span class="o">.</span><span class="n">model_dump</span><span class="p">())</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
</span><span id="BM25Model-264"><a href="#BM25Model-264"><span class="linenos">264</span></a>        <span class="n">scored_docs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">scores</span><span class="p">)]</span>
</span><span id="BM25Model-265"><a href="#BM25Model-265"><span class="linenos">265</span></a>        <span class="n">scored_docs</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="BM25Model-266"><a href="#BM25Model-266"><span class="linenos">266</span></a>        <span class="k">return</span> <span class="n">scored_docs</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">k</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>A Pydantic model for creating, loading, and searching BM25 indices.</p>

<p>Methods:</p>

<ul>
<li>create_model: Creates and saves a BM25 model for a set of tokenized document chunks.</li>
<li>load_model: Loads a BM25 model and tokenized documents from disk.</li>
<li>search: Performs a BM25 search on a tokenized query.</li>
</ul>

<p>Usage:</p>

<ul>
<li>Instantiate this class to create, load, and search BM25 indices.</li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            <div id="BM25Model.create_model" class="classattr">
                                        <input id="BM25Model.create_model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">create_model</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n"><a href="#TokenizedChunk">TokenizedChunk</a></span><span class="p">]</span>,</span><span class="param">	<span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="BM25Model.create_model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BM25Model.create_model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BM25Model.create_model-163"><a href="#BM25Model.create_model-163"><span class="linenos">163</span></a>    <span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span>
</span><span id="BM25Model.create_model-164"><a href="#BM25Model.create_model-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span id="BM25Model.create_model-165"><a href="#BM25Model.create_model-165"><span class="linenos">165</span></a>    <span class="p">):</span>
</span><span id="BM25Model.create_model-166"><a href="#BM25Model.create_model-166"><span class="linenos">166</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BM25Model.create_model-167"><a href="#BM25Model.create_model-167"><span class="linenos">167</span></a><span class="sd">        Creates and saves a BM25 model for a set of tokenized document chunks.</span>
</span><span id="BM25Model.create_model-168"><a href="#BM25Model.create_model-168"><span class="linenos">168</span></a>
</span><span id="BM25Model.create_model-169"><a href="#BM25Model.create_model-169"><span class="linenos">169</span></a><span class="sd">        Args:</span>
</span><span id="BM25Model.create_model-170"><a href="#BM25Model.create_model-170"><span class="linenos">170</span></a><span class="sd">        - `project_name (str)`: The name of the project.</span>
</span><span id="BM25Model.create_model-171"><a href="#BM25Model.create_model-171"><span class="linenos">171</span></a><span class="sd">        - `model_name (str)`: The name of the model.</span>
</span><span id="BM25Model.create_model-172"><a href="#BM25Model.create_model-172"><span class="linenos">172</span></a><span class="sd">        - `chunks (List[TokenizedChunk])`: The list of tokenized document chunks.</span>
</span><span id="BM25Model.create_model-173"><a href="#BM25Model.create_model-173"><span class="linenos">173</span></a><span class="sd">        - `kwargs (Dict[Any, Any])`: Additional arguments for BM25Okapi.</span>
</span><span id="BM25Model.create_model-174"><a href="#BM25Model.create_model-174"><span class="linenos">174</span></a>
</span><span id="BM25Model.create_model-175"><a href="#BM25Model.create_model-175"><span class="linenos">175</span></a><span class="sd">        Returns:</span>
</span><span id="BM25Model.create_model-176"><a href="#BM25Model.create_model-176"><span class="linenos">176</span></a><span class="sd">        - None</span>
</span><span id="BM25Model.create_model-177"><a href="#BM25Model.create_model-177"><span class="linenos">177</span></a>
</span><span id="BM25Model.create_model-178"><a href="#BM25Model.create_model-178"><span class="linenos">178</span></a><span class="sd">        Raises:</span>
</span><span id="BM25Model.create_model-179"><a href="#BM25Model.create_model-179"><span class="linenos">179</span></a><span class="sd">        - FileExistsError: If the model directory already exists.</span>
</span><span id="BM25Model.create_model-180"><a href="#BM25Model.create_model-180"><span class="linenos">180</span></a>
</span><span id="BM25Model.create_model-181"><a href="#BM25Model.create_model-181"><span class="linenos">181</span></a><span class="sd">        Usage:</span>
</span><span id="BM25Model.create_model-182"><a href="#BM25Model.create_model-182"><span class="linenos">182</span></a><span class="sd">        - `bm25.create_model(&quot;project&quot;, &quot;model&quot;, tokenized_chunks)`</span>
</span><span id="BM25Model.create_model-183"><a href="#BM25Model.create_model-183"><span class="linenos">183</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BM25Model.create_model-184"><a href="#BM25Model.create_model-184"><span class="linenos">184</span></a>        <span class="c1"># Create the model directory if it does not exist</span>
</span><span id="BM25Model.create_model-185"><a href="#BM25Model.create_model-185"><span class="linenos">185</span></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;./.OsireRAG&quot;</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span><span id="BM25Model.create_model-186"><a href="#BM25Model.create_model-186"><span class="linenos">186</span></a>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BM25Model.create_model-187"><a href="#BM25Model.create_model-187"><span class="linenos">187</span></a>
</span><span id="BM25Model.create_model-188"><a href="#BM25Model.create_model-188"><span class="linenos">188</span></a>        <span class="c1"># Create and save the BM25 model from the tokenized documents</span>
</span><span id="BM25Model.create_model-189"><a href="#BM25Model.create_model-189"><span class="linenos">189</span></a>        <span class="n">tokenized_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">chunk</span><span class="o">.</span><span class="n">tokens</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
</span><span id="BM25Model.create_model-190"><a href="#BM25Model.create_model-190"><span class="linenos">190</span></a>        <span class="n">bm25</span> <span class="o">=</span> <span class="n">BM25Okapi</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="BM25Model.create_model-191"><a href="#BM25Model.create_model-191"><span class="linenos">191</span></a>
</span><span id="BM25Model.create_model-192"><a href="#BM25Model.create_model-192"><span class="linenos">192</span></a>        <span class="c1"># Save the tokenized documents and model to disk</span>
</span><span id="BM25Model.create_model-193"><a href="#BM25Model.create_model-193"><span class="linenos">193</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;documents.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model.create_model-194"><a href="#BM25Model.create_model-194"><span class="linenos">194</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model.create_model-195"><a href="#BM25Model.create_model-195"><span class="linenos">195</span></a>
</span><span id="BM25Model.create_model-196"><a href="#BM25Model.create_model-196"><span class="linenos">196</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;data.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model.create_model-197"><a href="#BM25Model.create_model-197"><span class="linenos">197</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model.create_model-198"><a href="#BM25Model.create_model-198"><span class="linenos">198</span></a>
</span><span id="BM25Model.create_model-199"><a href="#BM25Model.create_model-199"><span class="linenos">199</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model.create_model-200"><a href="#BM25Model.create_model-200"><span class="linenos">200</span></a>            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">bm25</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Creates and saves a BM25 model for a set of tokenized document chunks.</p>

<p>Args:</p>

<ul>
<li><code>project_name (str)</code>: The name of the project.</li>
<li><code>model_name (str)</code>: The name of the model.</li>
<li><code>chunks (List[TokenizedChunk])</code>: The list of tokenized document chunks.</li>
<li><code>kwargs (Dict[Any, Any])</code>: Additional arguments for BM25Okapi.</li>
</ul>

<p>Returns:</p>

<ul>
<li>None</li>
</ul>

<p>Raises:</p>

<ul>
<li>FileExistsError: If the model directory already exists.</li>
</ul>

<p>Usage:</p>

<ul>
<li><code>bm25.create_model("project", "model", tokenized_chunks)</code></li>
</ul>
</div>


                            </div>
                            <div id="BM25Model.load_model" class="classattr">
                                        <input id="BM25Model.load_model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_model</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n"><a href="#TokenizedChunk">TokenizedChunk</a></span><span class="p">],</span> <span class="n">rank_bm25</span><span class="o">.</span><span class="n">BM25Okapi</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="BM25Model.load_model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BM25Model.load_model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BM25Model.load_model-202"><a href="#BM25Model.load_model-202"><span class="linenos">202</span></a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span>
</span><span id="BM25Model.load_model-203"><a href="#BM25Model.load_model-203"><span class="linenos">203</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="BM25Model.load_model-204"><a href="#BM25Model.load_model-204"><span class="linenos">204</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span> <span class="n">BM25Okapi</span><span class="p">]:</span>
</span><span id="BM25Model.load_model-205"><a href="#BM25Model.load_model-205"><span class="linenos">205</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BM25Model.load_model-206"><a href="#BM25Model.load_model-206"><span class="linenos">206</span></a><span class="sd">        Loads a BM25 model and tokenized documents from disk.</span>
</span><span id="BM25Model.load_model-207"><a href="#BM25Model.load_model-207"><span class="linenos">207</span></a>
</span><span id="BM25Model.load_model-208"><a href="#BM25Model.load_model-208"><span class="linenos">208</span></a><span class="sd">        Args:</span>
</span><span id="BM25Model.load_model-209"><a href="#BM25Model.load_model-209"><span class="linenos">209</span></a><span class="sd">        - `project_name (str)`: The name of the project.</span>
</span><span id="BM25Model.load_model-210"><a href="#BM25Model.load_model-210"><span class="linenos">210</span></a><span class="sd">        - `model_name (str)`: The name of the model.</span>
</span><span id="BM25Model.load_model-211"><a href="#BM25Model.load_model-211"><span class="linenos">211</span></a>
</span><span id="BM25Model.load_model-212"><a href="#BM25Model.load_model-212"><span class="linenos">212</span></a><span class="sd">        Returns:</span>
</span><span id="BM25Model.load_model-213"><a href="#BM25Model.load_model-213"><span class="linenos">213</span></a><span class="sd">        - Tuple[List[TokenizedChunk], BM25Okapi]: The tokenized documents and the BM25 model.</span>
</span><span id="BM25Model.load_model-214"><a href="#BM25Model.load_model-214"><span class="linenos">214</span></a>
</span><span id="BM25Model.load_model-215"><a href="#BM25Model.load_model-215"><span class="linenos">215</span></a><span class="sd">        Usage:</span>
</span><span id="BM25Model.load_model-216"><a href="#BM25Model.load_model-216"><span class="linenos">216</span></a><span class="sd">        - `tokenized_docs, bm25 = bm25.load_model(&quot;project&quot;, &quot;model&quot;)`</span>
</span><span id="BM25Model.load_model-217"><a href="#BM25Model.load_model-217"><span class="linenos">217</span></a>
</span><span id="BM25Model.load_model-218"><a href="#BM25Model.load_model-218"><span class="linenos">218</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="BM25Model.load_model-219"><a href="#BM25Model.load_model-219"><span class="linenos">219</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="BM25Model.load_model-220"><a href="#BM25Model.load_model-220"><span class="linenos">220</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BM25Model.load_model-221"><a href="#BM25Model.load_model-221"><span class="linenos">221</span></a>        <span class="c1"># Load the tokenized documents and BM25 model from disk</span>
</span><span id="BM25Model.load_model-222"><a href="#BM25Model.load_model-222"><span class="linenos">222</span></a>        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;./.OsireRAG&quot;</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span><span id="BM25Model.load_model-223"><a href="#BM25Model.load_model-223"><span class="linenos">223</span></a>
</span><span id="BM25Model.load_model-224"><a href="#BM25Model.load_model-224"><span class="linenos">224</span></a>        <span class="c1"># Load the documents</span>
</span><span id="BM25Model.load_model-225"><a href="#BM25Model.load_model-225"><span class="linenos">225</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;documents.pkl&quot;</span><span class="p">)),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model.load_model-226"><a href="#BM25Model.load_model-226"><span class="linenos">226</span></a>            <span class="n">tokenized_documents</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model.load_model-227"><a href="#BM25Model.load_model-227"><span class="linenos">227</span></a>
</span><span id="BM25Model.load_model-228"><a href="#BM25Model.load_model-228"><span class="linenos">228</span></a>        <span class="c1"># Load the BM25 model</span>
</span><span id="BM25Model.load_model-229"><a href="#BM25Model.load_model-229"><span class="linenos">229</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;model.pkl&quot;</span><span class="p">)),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="BM25Model.load_model-230"><a href="#BM25Model.load_model-230"><span class="linenos">230</span></a>            <span class="n">index</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="BM25Model.load_model-231"><a href="#BM25Model.load_model-231"><span class="linenos">231</span></a>
</span><span id="BM25Model.load_model-232"><a href="#BM25Model.load_model-232"><span class="linenos">232</span></a>        <span class="k">return</span> <span class="n">tokenized_documents</span><span class="p">,</span> <span class="n">index</span>
</span></pre></div>


            <div class="docstring"><p>Loads a BM25 model and tokenized documents from disk.</p>

<p>Args:</p>

<ul>
<li><code>project_name (str)</code>: The name of the project.</li>
<li><code>model_name (str)</code>: The name of the model.</li>
</ul>

<p>Returns:</p>

<ul>
<li>Tuple[List[TokenizedChunk], BM25Okapi]: The tokenized documents and the BM25 model.</li>
</ul>

<p>Usage:</p>

<ul>
<li><code>tokenized_docs, bm25 = bm25.load_model("project", "model")</code></li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            </div>
                            <div id="BM25Model.search" class="classattr">
                                        <input id="BM25Model.search-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">search</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">tokenized_query</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">model</span><span class="p">:</span> <span class="n">rank_bm25</span><span class="o">.</span><span class="n">BM25Okapi</span>,</span><span class="param">	<span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n"><a href="#TokenizedChunk">TokenizedChunk</a></span><span class="p">]</span>,</span><span class="param">	<span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n"><a href="chunker.html#Chunk">app.core.models.chunker.Chunk</a></span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="BM25Model.search-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BM25Model.search"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BM25Model.search-234"><a href="#BM25Model.search-234"><span class="linenos">234</span></a>    <span class="k">def</span> <span class="nf">search</span><span class="p">(</span>
</span><span id="BM25Model.search-235"><a href="#BM25Model.search-235"><span class="linenos">235</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BM25Model.search-236"><a href="#BM25Model.search-236"><span class="linenos">236</span></a>        <span class="n">tokenized_query</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
</span><span id="BM25Model.search-237"><a href="#BM25Model.search-237"><span class="linenos">237</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">BM25Okapi</span><span class="p">,</span>
</span><span id="BM25Model.search-238"><a href="#BM25Model.search-238"><span class="linenos">238</span></a>        <span class="n">chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TokenizedChunk</span><span class="p">],</span>
</span><span id="BM25Model.search-239"><a href="#BM25Model.search-239"><span class="linenos">239</span></a>        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="BM25Model.search-240"><a href="#BM25Model.search-240"><span class="linenos">240</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Chunk</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
</span><span id="BM25Model.search-241"><a href="#BM25Model.search-241"><span class="linenos">241</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BM25Model.search-242"><a href="#BM25Model.search-242"><span class="linenos">242</span></a><span class="sd">        Performs a BM25 search on a tokenized query.</span>
</span><span id="BM25Model.search-243"><a href="#BM25Model.search-243"><span class="linenos">243</span></a>
</span><span id="BM25Model.search-244"><a href="#BM25Model.search-244"><span class="linenos">244</span></a><span class="sd">        Args:</span>
</span><span id="BM25Model.search-245"><a href="#BM25Model.search-245"><span class="linenos">245</span></a><span class="sd">        - `tokenized_query (List[str])`: The tokenized query.</span>
</span><span id="BM25Model.search-246"><a href="#BM25Model.search-246"><span class="linenos">246</span></a><span class="sd">        - `model (BM25Okapi)`: The BM25 model to use for searching.</span>
</span><span id="BM25Model.search-247"><a href="#BM25Model.search-247"><span class="linenos">247</span></a><span class="sd">        - `chunks (List[TokenizedChunk])`: The list of tokenized document chunks.</span>
</span><span id="BM25Model.search-248"><a href="#BM25Model.search-248"><span class="linenos">248</span></a><span class="sd">        - `k (int)`: The number of top results to return.</span>
</span><span id="BM25Model.search-249"><a href="#BM25Model.search-249"><span class="linenos">249</span></a>
</span><span id="BM25Model.search-250"><a href="#BM25Model.search-250"><span class="linenos">250</span></a><span class="sd">        Returns:</span>
</span><span id="BM25Model.search-251"><a href="#BM25Model.search-251"><span class="linenos">251</span></a><span class="sd">        - List[Tuple[Chunk, float]]: A list of document chunks and their scores.</span>
</span><span id="BM25Model.search-252"><a href="#BM25Model.search-252"><span class="linenos">252</span></a>
</span><span id="BM25Model.search-253"><a href="#BM25Model.search-253"><span class="linenos">253</span></a><span class="sd">        Usage:</span>
</span><span id="BM25Model.search-254"><a href="#BM25Model.search-254"><span class="linenos">254</span></a><span class="sd">        - `results = bm25.search(tokenized_query, bm25_model, tokenized_chunks, k=10)`</span>
</span><span id="BM25Model.search-255"><a href="#BM25Model.search-255"><span class="linenos">255</span></a>
</span><span id="BM25Model.search-256"><a href="#BM25Model.search-256"><span class="linenos">256</span></a><span class="sd">        Author: Adam Haile  </span>
</span><span id="BM25Model.search-257"><a href="#BM25Model.search-257"><span class="linenos">257</span></a><span class="sd">        Date: 10/23/2024</span>
</span><span id="BM25Model.search-258"><a href="#BM25Model.search-258"><span class="linenos">258</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BM25Model.search-259"><a href="#BM25Model.search-259"><span class="linenos">259</span></a>        <span class="c1"># Perform the BM25 search</span>
</span><span id="BM25Model.search-260"><a href="#BM25Model.search-260"><span class="linenos">260</span></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_scores</span><span class="p">(</span><span class="n">tokenized_query</span><span class="p">)</span>
</span><span id="BM25Model.search-261"><a href="#BM25Model.search-261"><span class="linenos">261</span></a>
</span><span id="BM25Model.search-262"><a href="#BM25Model.search-262"><span class="linenos">262</span></a>        <span class="c1"># Sort the chunks by score and return the top k results</span>
</span><span id="BM25Model.search-263"><a href="#BM25Model.search-263"><span class="linenos">263</span></a>        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Chunk</span><span class="p">(</span><span class="o">**</span><span class="n">chunk</span><span class="o">.</span><span class="n">model_dump</span><span class="p">())</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">]</span>
</span><span id="BM25Model.search-264"><a href="#BM25Model.search-264"><span class="linenos">264</span></a>        <span class="n">scored_docs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">scores</span><span class="p">)]</span>
</span><span id="BM25Model.search-265"><a href="#BM25Model.search-265"><span class="linenos">265</span></a>        <span class="n">scored_docs</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="BM25Model.search-266"><a href="#BM25Model.search-266"><span class="linenos">266</span></a>        <span class="k">return</span> <span class="n">scored_docs</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">k</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Performs a BM25 search on a tokenized query.</p>

<p>Args:</p>

<ul>
<li><code>tokenized_query (List[str])</code>: The tokenized query.</li>
<li><code>model (BM25Okapi)</code>: The BM25 model to use for searching.</li>
<li><code>chunks (List[TokenizedChunk])</code>: The list of tokenized document chunks.</li>
<li><code>k (int)</code>: The number of top results to return.</li>
</ul>

<p>Returns:</p>

<ul>
<li>List[Tuple[Chunk, float]]: A list of document chunks and their scores.</li>
</ul>

<p>Usage:</p>

<ul>
<li><code>results = bm25.search(tokenized_query, bm25_model, tokenized_chunks, k=10)</code></li>
</ul>

<p>Author: Adam Haile<br />
Date: 10/23/2024</p>
</div>


                            </div>
                            <div id="BM25Model.model_config" class="classattr">
                                <div class="attr variable">
            <span class="name">model_config</span><span class="annotation">: ClassVar[pydantic.config.ConfigDict]</span>        =
<span class="default_value">{}</span>

        
    </div>
    <a class="headerlink" href="#BM25Model.model_config"></a>
    
            <div class="docstring"><p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>
</div>


                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>